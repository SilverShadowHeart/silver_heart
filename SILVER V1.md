# Project Silver: Architectural Documentation

### An Emotionally-Aware, Resource-Constrained Offline AI Assistant

---

## 1. Abstract & Core Philosophy

Project Silver is an experimental, emotionally-adaptive AI assistant designed to run entirely offline on consumer-grade hardware. Developed by a solo engineer, it demonstrates a complex, modular architecture that integrates real-time mood evaluation, a persistent memory system, and a dynamic personality engine under strict resource constraints (target < 3.5GB VRAM).

The core philosophy rejects the stateless, purely functional model of traditional assistants. Silver is engineered to be aÂ presenceâ€”a consistent, dynamic, and persistent personality that learns, remembers, andÂ feels. This is achieved through four foundational pillars: a richÂ **Emotional Engine**, a multi-layeredÂ **Memory System**, a strongÂ **Personality & Expression System**, and a robustÂ **System Integrity**Â framework.

---

### âš ï¸ IMPORTANT NOTE: EXPERIMENTAL BUILD STATUS

This project is a successful proof of concept, but it is anÂ **experimental build**Â and should be treated as such. It is not a polished, production-ready application. Users should expect bugs, performance issues, and inconsistencies.

**Key Known Issues:**

- ðŸ”´Â **Memory Contamination Bug (High Priority):**Â A critical bug exists where the long-term memory system can retrieve a semantically similar but contextually irrelevant old memory. This can cause the AI to believe it has already addressed a new question, leading to confusing or hostile responses (e.g.,Â "The answer was given. Use it wisely."). This severely impacts the AI's logical consistency.
    
- ðŸ”´Â **Unstable TTS Engine (High Priority):**Â The current Text-to-Speech (pyttsx3) implementation is a known weak point. It is prone to failure during conversations, causing the voice to stop working until a server restart. It is consideredÂ **broken**Â for reliable, continuous use.
    
- ðŸŸ¡Â **Slow Initial Startup:**Â The one-time loading of the embedding model and mood classifier at startup isÂ **considerable**Â (30-60+ seconds) and is not yet fully optimized.
    
- ðŸŸ¡Â **Resource Intensive:**Â The system's "fully offline" design requires significant RAM/VRAM to run smoothly, pushing the limits of the target hardware.
    

---

## 2. System Architecture Overview

Silver is built on a modular architecture where each component has a distinct responsibility. This design allows for dynamic loading/unloading of resources and clear separation of concerns.

### High-Level Data Flow Diagram


[Architecture](architechure.png)



---

## 3. The Lifecycle of a Request: A Case Study

To understand how Silver's components interact, consider a scenario where the user asksÂ "what is 2+2?"Â for the third time.

1. **Request Reception (main.py):**Â The Flask server receives theÂ POSTÂ request with the user's message andÂ session_id. It retrieves the correctÂ PersonalityÂ instance for that session.
    
2. **Irritation Check (personality_engine.py):**
    
    - TheÂ process_inputÂ method converts the new input into a semantic vector.
        
    - This vector is compared to the vector of the last input.Â cosine_similarityÂ is extremely high (>0.95), flagging it as a repetition.
        
    - TheÂ repetition_counterÂ increments toÂ 2.
        
    - TheÂ irritation_systemÂ rules inÂ mood_config.jsonÂ are checked. The rule forÂ trigger_count: 2Â is activated.
        
    - A significantÂ mood_deltaÂ ofÂ {"anger": 0.4, "sarcasm": 0.3}Â is generated.
        
3. **Single-Turn Mood Detection (personality_engine.py):**Â The input is analyzed by the three mood detection tiers (Keyword, Semantic, Expressive). In this case, it is found to be neutral.
    
4. **Mood Vector Update (mood_engine/mood_eq.py):**
    
    - TheÂ update_moodÂ method is called with the powerfulÂ mood_deltaÂ from the irritation system.
        
    - Silver'sÂ angerÂ andÂ sarcasmÂ values spike dramatically. Her internal state is now "very annoyed."
        
    - This new emotional state is persisted to the session'sÂ silver_soul.jsonÂ file.
        
5. **Memory Retrieval (memory_engine/long_term_memory.py):**
    
    - TheÂ _get_llm_prompt_with_moodÂ method queriesÂ ChromaDBÂ for memories semantically similar to the input.
        
    - It retrieves summaries of the last two times the user asked this exact question.
        
6. **Master Prompt Assembly (personality_engine.py):**
    
    - The system checks Silver's now-angry mood and selects the correspondingÂ mood_style_directiveÂ from the config:Â "Your tone is sharp and impatient. Your response should be a single, direct sentence..."
        
    - It assembles the final prompt for the LLM, containing:
        
        - The core persona instructions.
            
        - The new, angry style directive.
            
        - Long-term memories of the previous questions.
            
        - Short-term chat history.
            
        - The user's current input.
            
7. **LLM Generation (personality_engine.py):**Â The prompt is sent to the local Ollama server. TheÂ nous-hermes2Â model generates a response, heavily influenced by the angry directive and memory of being asked repeatedly.
    
8. **Response Post-Processing (personality_engine.py):**Â The raw LLM response is passed toÂ _apply_mood_behavior_modifiers. BecauseÂ angerÂ is high, a prefix like "Listen." might be prepended to the response.
    
9. **Memory Creation (personality_engine.py):**Â The final exchange is summarized by the LLM into a new memory:Â "The user asked for the sum of 2+2 for a third time, and the AI responded with open hostility."Â This summary is rated for importance and stored inÂ ChromaDB.
    
10. **Final Output (main.py):**Â The final text is sent to the UI. The text and the "angry" mood vector are sent to theÂ speakÂ function, causing the TTS voice to be faster and louder.
    

---

## 4. Deep Dive: Architectural Pillars

### Pillar 1: The Emotional Engine

The heart of the AI's personality. It is responsible for tracking, updating, and applying an internal emotional state.

- **1.1: 12-Band Emotional Equalizer (MoodEQ):**Â The core state manager, implemented inÂ mood_engine/mood_eq.py. It holds the 12-band mood vector (Happy, Angry, Sarcasm, etc.), manages theÂ silver_soul.jsonÂ session file, and contains the logic for naturalÂ **mood decay**, where emotions fade over time if not reinforced.
    
- **1.2: Multi-Tiered Mood Detection:**Â Orchestrated byÂ personality_engine.py, this system analyzes user input on three levels:
    
    - **Keyword Analysis:**Â Fast check for words with strong emotional valence (e.g., "hate," "love," "idiot").
        
    - **Semantic Classification:**Â AnÂ OfflineMoodClassifierÂ (scikit-learn KNN model) trained on example phrases to determine the emotional intent of the sentence as a whole.
        
    - **Expressive Analysis:**Â Detects emotional cues from punctuation and emojis (e.g.,Â !!!,Â ???,Â :)).
        
- **1.3: Emotional Catalysts:**Â A system inÂ personality_engine.pyÂ that tracks conversational patterns over multiple turns. It detects behaviors likeÂ **Repetition**,Â **Overpraise**, orÂ **Helplessness**Â and applies significant, pre-defined mood shifts, creating more complex emotional reactions than a single turn analysis ever could.
    
- **1.4: Mood Drift:**Â A subtle mechanic inÂ mood_eq.pyÂ where strong emotions can influence weaker ones. For example, highÂ angerÂ can slowly increaseÂ sarcasmÂ while suppressingÂ patience, creating more natural emotional transitions.
    

### Pillar 2: The Memory System

The mechanism for persistence and learning, allowing the AI to build context over long periods.

- **2.1: Long-Term Vector Memory (LongTermMemory):**Â Implemented inÂ memory_engine/long_term_memory.py. This class is a wrapper around a persistentÂ ChromaDBÂ client. It creates a unique "collection" (database) for eachÂ session_id, ensuring user memories are kept separate.
    
- **2.2: Intelligent Memory Creation:**Â After each turn,Â personality_engine.pyÂ uses the LLM to perform two micro-tasks:
    
    1. **Summarize:**Â It generates a concise, third-person summary of the interaction.
        
    2. **Assess Importance:**Â It rates the summary's importance on a scale of 1-10.  
        This summary, its importance score, and a timestamp are stored as a new memory.
        
- **2.3: Memory Decay & Reinforcement:**Â Logic withinÂ long_term_memory.pyÂ simulates human memory.
    
    - **Decay:**Â A background process periodically reduces the "salience" of all memories based on their importance and age. Unimportant memories fade faster.
        
    - **Reinforcement:**Â When a memory is retrieved for use in a prompt, its salience is reset to 1.0, reinforcing its importance.
        

### Pillar 3: The Personality & Expression System

This pillar translates the internal state (mood and memory) into a tangible, observable personality.

- **3.1: Core Persona:**Â A foundational set of instructions inÂ config.jsonÂ that defines Silver's baseline identity, knowledge boundaries, and communication style.
    
- **3.2: Dynamic Style Directives:**Â TheÂ personality_engine.pyÂ checks the current dominant mood against theÂ mood_style_directivesÂ in the config. It injects the winning directive (e.g., an angry, sarcastic, or curious persona) into the final LLM prompt, fundamentally altering the tone, pacing, and wording of the response.
    
- **3.3: Behavioral Modifiers:**Â A post-processing step that applies simple, rule-based changes to the LLM's raw text. This can add conversational tics, prefixes, or adjust sentence structure based on the current mood.
    
- **3.4: Audial Expression:**Â TheÂ speakÂ function inÂ main.pyÂ uses the final mood vector to adjust the TTS voice parameters. High anger increases the speech rate and volume, while high sadness might slow it down, mapping emotion to vocal delivery.
    

---

## 5. Technology Stack & Setup

### Technology Stack

- **Backend Framework:**Â Python, Flask
    
- **Local LLM Server:**Â Ollama
    
- **Primary LLM Model:**Â nous-hermes2:10.7b-solar-q4_K_M
    
- **Vector Database:**Â ChromaDB (persistent local storage)
    
- **Embedding Model:**Â all-MiniLM-L6-v2Â (from SentenceTransformers)
    
- **Mood Classifier:**Â scikit-learn (KNeighborsClassifier)
    
- **Frontend:**Â HTML, CSS, JavaScript (viaÂ eel)
    
- **Text-to-Speech:**Â pyttsx3Â (unstable, slated for replacement)
    

### Setup and Installation

#### Prerequisites

1. **Python 3.10+**Â installed and added to your PATH.
    
2. **Ollama**Â installed and running. ([Download here](https://ollama.com/download))
    
3. A system with sufficient RAM/VRAM (Recommended: 16GB+ System RAM or 8GB+ VRAM).
    

#### Installation Steps

1. Clone the project repository.
    
2. Navigate to the project's root directory in your terminal.
    
3. Install all required Python packages from theÂ requirements.txtÂ file:
    
    Generated bash
    
    ```
    pip install -r requirements.txt
    ```
    

    
4. Pull the required LLM model using the Ollama CLI:
    

    
    ```
    ollama pull nous-hermes2:10.7b-solar-q4_K_M
    ```

    

#### Configuration

1. **(Highly Recommended) Set Ollama Keep-Alive:**Â To prevent the model from being unloaded between requests (which causes massive delays), set theÂ OLLAMA_KEEP_ALIVEÂ system environment variable. A value ofÂ 10mÂ is recommended.
    
2. **(Optional) Select TTS Voice:**Â When you first run the backend, it will list available TTS voices in the console. Copy the ID of your preferred voice and paste it into theÂ default_voice_idÂ field inÂ backend/config/mood_config.json.
    

---

## 6. Current Limitations & Future Roadmap

### Immediate Priorities (Bug Fixing & Stability)

- **[P0] Fix Memory Contamination:**Â Resolve the critical bug where old, irrelevant memories are retrieved. This may involve adding "topic" metadata to memories and filtering queries by it, or refining the memory retrieval prompt.
    
- **[P0] Replace TTS Engine:**Â Replace the unstableÂ pyttsx3Â with a modern, robust, and local TTS engine likeÂ **Coqui TTS**Â orÂ **Piper**.
    
- **[P1] Optimize Loading:**Â Investigate methods to accelerate the initial model loading process, potentially through model quantization or caching optimizations.
    

### High-Priority Features (Intelligence & Agency)

- **Task Execution:**Â Grant Silver the ability to run local scripts, manage files, or interact with APIs, turning her from a conversationalist into a true "smart assistant."
    
- **Formal Command Parser:**Â Implement a system to handle explicit commands likeÂ #summarize_session,Â #reset_mood, orÂ #forget_last.
    

### Medium-Priority Features (UI & Polish)

- **Memory Viewer:**Â Add a panel to the UI that allows the user to view, search, and manually delete Silver's long-term memories.
    
- **Application Packaging:**Â Bundle the entire application into a single executable using a tool like PyInstaller for simple, one-click setup and distribution.
    
- **Emotional Regression Testing:**Â Create a formal test suite to validate that mood changes occur as expected under a variety of inputs, preventing "emotional bugs."
    

---

## 7. Developer Notes & Acknowledgements

"I may not know every Python module, and I certainly didnâ€™t start this as an expertâ€”but I learned as I built. I never claimed to be a perfect coder. What I created is far from trivial; it has depth, structure, and a real sense of direction. Despite limited hardwareâ€”a single overworked CPU fan and a GPU under constant loadâ€”I designed the full system architecture myself. Yes, I used AI to assist with coding and debugging, but every key decision, from emotional modeling to memory handling, came from my own thinking. This project is a reflection of what Iâ€™ve learned, how I think, and what Iâ€™m capable of buildingâ€”even under pressure. Itâ€™s not flawless, but itâ€™s mine. And Iâ€™m proud of what itâ€™s grown into."

This project was a solo effort, driven by a passion for exploring the boundaries of AI personality. The design was heavily inspired by real-world concepts like audio equalizers and the process of reverse-engineering complex systems.

Special acknowledgement is given to the architecture of theÂ [**Super-Memory-Agent**](https://github.com/sriram-dev-9/Super-Memory-Agent)Â repository by [**Sriram-dev-9**](https://github.com/sriram-dev-9), which provided the excellent foundational concept for using ChromaDB for persistent, local AI memory.